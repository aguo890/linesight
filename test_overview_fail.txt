============================= test session starts =============================
platform win32 -- Python 3.13.5, pytest-9.0.2, pluggy-1.6.0 -- C:\Users\19803\Projects\FactoryExcelManager\backend\venv\Scripts\python.exe
cachedir: .pytest_cache
rootdir: C:\Users\19803\Projects\FactoryExcelManager\backend
configfile: pytest.ini
plugins: anyio-4.12.1, Faker-40.1.0, langsmith-0.6.1, asyncio-1.3.0, cov-7.0.0, mock-3.15.1
asyncio: mode=Mode.AUTO, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
collecting ... collected 1 item

backend\tests\test_api\test_analytics_real.py::test_get_overview_stats_real FAILED [100%]

================================== FAILURES ===================================
________________________ test_get_overview_stats_real _________________________

async_client = <httpx.AsyncClient object at 0x000001BDDF80FB60>
auth_headers = {'Authorization': 'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE3NzE3NzQ2ODIsInN1YiI6IjM4YzBjNDVlLWEwMjgtNGY1NS1hYjdlLTkwYzEyM2YwNjQzNyIsImlhdCI6MTc3MTE2OTg4Mn0.2N9Q84RFtTV1q2FXIrYz5C1HS636n7HZB-_3eyV61NI'}
analytics_data = {'record': <TraceabilityRecord(id=8aa667e3-e95a-4f57-930a-f106bd76f842, standard=ComplianceStandard.UFLPA)>, 'run': <P...9-5d5524d58393, employee_id=WK-001)>, 'worker2': <Worker(id=9669d96a-e1bc-495a-a94c-687d8f66031e, employee_id=WK-002)>}

    @pytest.mark.asyncio
    async def test_get_overview_stats_real(
        async_client: AsyncClient, auth_headers: dict, analytics_data
    ):
        response = await async_client.get(
            "/api/v1/analytics/overview", headers=auth_headers
        )
        assert response.status_code == 200
        data = response.json()
        # Verify stats based on analytics_data
        assert data["total_output"] == 450  # From run.actual_qty
        # efficiency returned as float/decimal
        # Calculated: Earned(4500) / Available(10*4800=48000) = 9.375%
        # AnalyticsService rounds to 2 decimals -> 9.38
        assert abs(float(data["avg_efficiency"]) - 9.38) < 0.1
        assert data["active_lines"] >= 1
>       assert data["discrepancies_count"] >= 1
E       assert 0 >= 1

backend\tests\test_api\test_analytics_real.py:145: AssertionError
---------------------------- Captured stdout call -----------------------------
{"timestamp": "2026-02-15T15:38:02.750892Z", "level": "INFO", "logger": "app.api.v1.endpoints.analytics", "message": "[DIAG] get_overview_stats called with line_id=None"}
{"timestamp": "2026-02-15T15:38:02.771780Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET http://test/api/v1/analytics/overview \"HTTP/1.1 200 OK\""}
------------------------------ Captured log call ------------------------------
INFO     app.api.v1.endpoints.analytics:analytics.py:73 [DIAG] get_overview_stats called with line_id=None
INFO     httpx:_client.py:1740 HTTP Request: GET http://test/api/v1/analytics/overview "HTTP/1.1 200 OK"
=========================== short test summary info ===========================
FAILED backend\tests\test_api\test_analytics_real.py::test_get_overview_stats_real - assert 0 >= 1
============================== 1 failed in 2.03s ==============================
